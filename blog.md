### Discussing Algorithmic Criticisms by Stephen Ramsay



Digital text analysis and visual representation have become a prominent form of literary analysis.  They can provide scholars, teachers, and students with a deeper understanding of literary texts. These new ways of analysis, such as visual and graphical quantitative formats, can expand our understanding of a text, or possibly give an entirely new meaning.  In Reading Machines by Stephen Ramsay, section 1, An Algorithmic Criticism, discusses how these digital tools are shaping the way critics formulate interpretations about literary texts. Ramsay also discusses how some literary critics don’t feel these tools have a place in the humanities. Two central themes of Algorithmic Criticism are quantitative versus qualitative information and literary text analysis. These themes provide background for my supporting argument for the use of digital text analysis and digital interpretation in the humanities.

Human interpretation is an individual’s own analysis, assessment, and conclusion of anything the body can interact with through its senses. In the 21st century, we use our technology as an extension of our senses both physically and mentally, more so than any other time in history. This extension of digital technology is widely accepted in the science and business world, but seems to fall short in the humanities. Ramsay explains that “It is not difficult to see why a contemporary criticism temperamentally and philosophically at peace with intuition and serendipity would choose to ignore the corrective tendencies of the computer against the deficiencies of "human reading:' Text analysis arises to assist the critic, but only if the critic agrees to operate within the regime of scientific methodology with its "refutations" of hypotheses.” (Ramsay, 2011). From this, it can be inferred that certain critics see digital text analysis as limiting, and would argue for more traditional ways of text analysis in order keep the humanities strictly human. The corrective tendencies of the computer (referred to in the quote above), is exactly what Algorithmic Criticism is about. Interpretation of the humanities is largely subjective, if not completely so. But how can an objective-based machine possibly provide the necessary qualitative data required for accepted interpretation? A simple answer is that it can’t. The purpose of computers can be largely misinterpreted when giving them a place in literary text analysis and the humanities in general.

There is still alot to be said about human interpretation. In some cases, computers can’t compete with our ability to correlate ideas and information through empirical and hermeneutical inquiry. Ramsay uses Miriam Wallace’s research of the 1931 novel The Waves by Virginia Woolf as a good example of this. Wallace suggests that, “Focusing on the narrative construction of subjectivity reveals the pertinence of The Waves for current feminist reconfigurations of the feminine subject. This focus links the novel's visionary limitations to the historic moment of Modernism” (Wallace, 2000)(2011). This interpretation is reached through pure observation and analysis of the text, but also by going outside of the subject are of the novel and looking at intangible yet important concepts like feminism. This theory is one that cannot likely be drawn from digital text analysis due to the complexity of the correlating ideas involved. While this theory is extremely interesting and thought provoking, it does not provide a concrete answer or solution to anything. But as Ramsay puts it, “We are not trying to solve Woolf. We are trying to ensure that discussion of The Waves continues”. (Ramsay, 2011) This is the key to understanding the misinterpretation of computers in the humanities. They are not supposed be used for providing answers, but rather for assisting in the continuation and development of literary criticisms, text analysis, and humanities conversations of all types.
	
In order to realize the true potential of machines in the humanities, we must look out side of the humanities, and explore how other fields use digital tools for their scholarly conversations. Quite often, hermeneutical and empirical approaches are seen as completely different ways of thinking. New research has shown that the use of digital text analysis has allowed hermeneutical and empirical thinkers to collaborate. In her research paper Re-imagining the Cambridge School in the Age of Digital Humanities, Jennifer London explores this collaboration. In the world of political science, there is a new hermeneutical circle that is evolving (London, 2016). This new circle aims to bring hermeneutical and empirical political scientists together, and have each approach and challenge the other. London ends her research by saying “they would both come to meditate on the complex relations between textual and algorithmic forms of representation, and what might be lost in translation from one to another” (2016). Here, she explains that both hermeneutical and empirical thinkers in political science can come together and assist each other through in understanding new digital representation. This is an important example of how quantitative and qualitative data are being combined and interpreted in fields other than the digital humanities. 

Digital text analysis tools take on a number of different forms, and serve different purposes for academics and scholars alike. Some of the tools used in research and exploration are free, easy to use, and can provide in a variety of interesting and important comparative data. The first example of this is a tool called Voyant. This online tool is designed to analyze text files or text pasted from a computer clipboard. Once the text is entered, the user can visualize the text in the forms of graphs, plots, and other visual forms such as the Cirrus(pictured below). Voyant is useful for visualizing the most frequent words, or common phrases within one or multiple texts. As well, every analysis tool within voyant can be exported into code, or as an image. A second tool that is useful for interpretation is Neatline. Neatline is a geospatial-based tool that can create interactive maps and stories through its open source software. Neatline was created with the idea that visualization in the humanities is about the process, rather than the result (Nowviskie, 2011).


By the end of Algorithmic Criticisms, Ramsay explains that digital criticism needs a drastic change, not just by design, but by how the humanities community sees it. I feel that Ramsay sees the bigger picture when he says “the ambit of these ways and forms need not be constrained by a hermeneutics that disallows the connotative and analogical methods of criticism” (Ramsay, 2011). He wants to see something like the new hermeneutical circle that London et al discusses, in the world of the digital humanities. While the purpose of digital criticism may not always be clear, it can play a very important role in discovering new ways to interpret textual information. In order to gain the full potential of the digital humanities, we must use our machines to provide us with quantitative information that can create qualitative criticisms that can lead to new and exciting interpretations.


	

Works Cited:

    London, Jennifer A. “Re-Imagining the Cambridge School in the Age of Digital Humanities.” Annual Review of Political Science 19      	
    (2016): 351–373. Scholars Portal Journals. Web.
    
    Nowviskie, Bethany. "Neatline & visualization as interpretation." Bethany Nowviskie. N.p., 02 Nov. 2014. Web. 10 Mar. 2017.

    Ramsay, Stephen. Reading machines: toward an algorithmic criticism. Urbana, IL: U of Illinois Press, 2012. Print.

    “Voyant Tools.” N.p., n.d. Web. 10 Mar. 2017.

    


